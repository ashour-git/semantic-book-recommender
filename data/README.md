# Data Directory

This directory contains generated data files from the notebooks.

## Files

### Generated Files (Git Ignored)

These files are generated by running the Jupyter notebooks and are excluded from version control due to their size:

- **`books_with_categories.csv`** (6.2 MB)
  - Source: `notebooks/text-classification.ipynb`
  - Contains: Book data with Fiction/Nonfiction classifications
  - Fields: Original fields + `simple_categories`

- **`books_with_emotions.csv`** (6.9 MB)
  - Source: `notebooks/sentiment-analysis.ipynb`
  - Contains: Book data with emotion scores
  - Fields: Original fields + emotion scores (anger, disgust, fear, joy, sadness, surprise, neutral)

- **`tagged_description.txt`** (2.5 MB)
  - Source: `notebooks/sentiment-analysis.ipynb`
  - Contains: Tagged descriptions for analysis

## Generating Data Files

To generate these files locally:

1. **Run the notebooks in order:**
   ```bash
   jupyter notebook
   ```

2. **Execute:**
   - `notebooks/data-exploration.ipynb` → Creates `../books_cleaned.csv`
   - `notebooks/text-classification.ipynb` → Creates `books_with_categories.csv`
   - `notebooks/sentiment-analysis.ipynb` → Creates `books_with_emotions.csv`

3. **Or download from the production app** (if available)

## For Developers

If you're cloning this repository, you'll need to either:

1. **Generate the files** by running the notebooks, or
2. **Download sample data** from [releases](https://github.com/ashour-git/semantic-book-recommender/releases) (if available)

The main application (`app.py`) will work with just `books_cleaned.csv` (included in repo). Emotion filtering requires `books_with_emotions.csv`.

## Note

These files are gitignored because:
- Large file sizes (6-7 MB each)
- Can be regenerated from source data
- Keeps repository size manageable
